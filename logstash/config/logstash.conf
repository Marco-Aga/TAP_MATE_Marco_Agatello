input { 
  # Input HTTP per recuperare i dati dal sensore in tempo reale
  http_poller {
    urls => {
        test1 => {
        method => "get"
        url => "https://api.switch-bot.com/v1.0/devices/FC881F927CB8/status"
        headers => {
            "authorization" => "${TAP_TOKEN}"
            "Content-Type" => "application/json"
            "charset" => "utf-8"
            "Accept" => "text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2"
            "Accept-Encoding" => "text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2"
            }
        }
    }
    request_timeout => 60
    schedule => { every => "10s" }
    codec => "json"
   }
  # Input per leggere i dati dal file CSV, in questo caso il file viene riletto ad ogni avvio di Logstash
  file {
    path => "/usr/share/logstash/Buffer/termometro_data.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }

}

# Filtro per i dati per apporrate le varie modifiche
filter {
  # Filtro per i dati provenienti dal file CSV 
  csv {
    separator => ","
    columns => ["Timestamp", "Temperature_Celsius", "Relative_Humidity"]
    skip_header => true
  }
  # Filtro per convertire i dati in formato corretto, per i dati HTTP darà ovviamente errore, essendo che non trova il campo "Timestamp", ma non è un problema
  date {
    match => ["Timestamp", "YYYY-MM-dd HH:mm"]
    timezone => "Europe/Rome"
    target => "Timestamp"
  }
  # Filtro per i dati provenienti dall'input HTTP 
  if [body] {
    mutate {
      rename => { "[body][temperature]" => "Temperature_Celsius" }
      rename => { "[body][humidity]" => "Relative_Humidity" }
      rename => { "@timestamp" => "Timestamp" }
      remove_field => ["@version", "body", "event", "statusCode", "message"]
    }
  }
  # Filtro per eliminare i dati che non sono validi
  if [message] =~ /^Date,/ {
      drop { }
  }
}

# Output per inviare i dati al topic di Kafka
output {
  kafka {
    topic_id => "stream_input"
    bootstrap_servers => "PLAINTEXT://kafka:9092"
    value_serializer => "org.apache.kafka.common.serialization.StringSerializer"
    key_serializer => "org.apache.kafka.common.serialization.StringSerializer"
    message_key => "Sensor"
    codec => "json"
  }
}